{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a multilingual topic classification model for Q&A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "# from webfaq.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretained_model_name = \"xlm-roberta-base\"\n",
    "finetuned_model_name = \"webfaq-topic-classification_2\"\n",
    "\n",
    "resources_dir = os.path.join(\"..\", \"..\", \"..\", \"..\", \"resources\")\n",
    "model_dir = os.path.join(\"..\", \"..\", \"..\", \"..\", \"models\", finetuned_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['language', 'label', 'question', 'answer', 'title', 'description'],\n",
       "        num_rows: 63720\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['language', 'label', 'question', 'answer', 'title', 'description'],\n",
       "        num_rows: 7965\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['language', 'label', 'question', 'answer', 'title', 'description'],\n",
       "        num_rows: 7965\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotations file\n",
    "annotations_path = os.path.join(resources_dir, \"tc_annotations.jsonl\")\n",
    "\n",
    "# Add test split\n",
    "dataset = Dataset.from_json(annotations_path)\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Add validation split\n",
    "dataset_validation_test = dataset[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "dataset[\"validation\"] = dataset_validation_test[\"train\"]\n",
    "dataset[\"test\"] = dataset_validation_test[\"test\"]\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa</td>\n",
       "      <td>7</td>\n",
       "      <td>¿22 bet es legal en Argentina?</td>\n",
       "      <td>Sí. La marca no cuenta con una licencia local,...</td>\n",
       "      <td>22 Bet: La mejor casa de apuestas deportivas y...</td>\n",
       "      <td>Descubra la emoción de las apuestas deportivas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jpn</td>\n",
       "      <td>2</td>\n",
       "      <td>Guangzhou Baiyun International Airportからホテルまでの...</td>\n",
       "      <td>Vaperse Hotel Guangzhou 空港へ28.4km。</td>\n",
       "      <td>Vaperse Hotel Guangzhou - 予約ウェブサイト</td>\n",
       "      <td>Vaperse Hotel Guangzhou, 広州のCBD珠江新城の中心地、金穂路にあり...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ukr</td>\n",
       "      <td>4</td>\n",
       "      <td>Як приєднатися до партнерської програми?</td>\n",
       "      <td>Щоб приєднатися до партнерської програми BetWi...</td>\n",
       "      <td>Партнерство в BetWinner - ваше нове джерело до...</td>\n",
       "      <td>Реєструйся в партнерській програмі BetWinner і...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dan</td>\n",
       "      <td>7</td>\n",
       "      <td>Hvem skal have styr på årsregnskabets frist?</td>\n",
       "      <td>Generelt er det ledelsen af virksomheden som s...</td>\n",
       "      <td>Årsregnskab frist - Hold styr på regler ang. å...</td>\n",
       "      <td>Har du svært ved at holde styr på regler, såso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bul</td>\n",
       "      <td>3</td>\n",
       "      <td>Мога ли да резервирам онлайн и кога ще получа ...</td>\n",
       "      <td>Резервацията се прави в няколко лесни стъпки, ...</td>\n",
       "      <td>Балеаж — Модерно боядисване и кичури • Reserva...</td>\n",
       "      <td>Балеаж с професионални фризьори! Виж цени, про...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  label                                           question  \\\n",
       "0      spa      7                     ¿22 bet es legal en Argentina?   \n",
       "1      jpn      2  Guangzhou Baiyun International Airportからホテルまでの...   \n",
       "2      ukr      4           Як приєднатися до партнерської програми?   \n",
       "3      dan      7       Hvem skal have styr på årsregnskabets frist?   \n",
       "4      bul      3  Мога ли да резервирам онлайн и кога ще получа ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Sí. La marca no cuenta con una licencia local,...   \n",
       "1                 Vaperse Hotel Guangzhou 空港へ28.4km。   \n",
       "2  Щоб приєднатися до партнерської програми BetWi...   \n",
       "3  Generelt er det ledelsen af virksomheden som s...   \n",
       "4  Резервацията се прави в няколко лесни стъпки, ...   \n",
       "\n",
       "                                               title  \\\n",
       "0  22 Bet: La mejor casa de apuestas deportivas y...   \n",
       "1                 Vaperse Hotel Guangzhou - 予約ウェブサイト   \n",
       "2  Партнерство в BetWinner - ваше нове джерело до...   \n",
       "3  Årsregnskab frist - Hold styr på regler ang. å...   \n",
       "4  Балеаж — Модерно боядисване и кичури • Reserva...   \n",
       "\n",
       "                                         description  \n",
       "0  Descubra la emoción de las apuestas deportivas...  \n",
       "1  Vaperse Hotel Guangzhou, 広州のCBD珠江新城の中心地、金穂路にあり...  \n",
       "2  Реєструйся в партнерській програмі BetWinner і...  \n",
       "3  Har du svært ved at holde styr på regler, såso...  \n",
       "4  Балеаж с професионални фризьори! Виж цени, про...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_all = pd.concat([dataset[\"train\"].to_pandas(), dataset[\"validation\"].to_pandas(), dataset[\"test\"].to_pandas()])\n",
    "df_dataset_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    23170\n",
       "2    11076\n",
       "3     5756\n",
       "4    23103\n",
       "5     4739\n",
       "6     5087\n",
       "7     3583\n",
       "8     3136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_all[\"label\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "afr     119\n",
       "ara    2000\n",
       "aze     457\n",
       "bel     111\n",
       "ben     626\n",
       "       ... \n",
       "ukr    2000\n",
       "urd     227\n",
       "uzb     312\n",
       "vie    2000\n",
       "zho    2000\n",
       "Name: count, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_all[\"language\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"afr\", \"ara\", \"aze\", \"bel\", \"ben\", \"bos\", \"bul\", \"cat\", \"ces\", \"dan\"\n",
      "\"deu\", \"ell\", \"eng\", \"est\", \"eus\", \"fas\", \"fin\", \"fra\", \"glg\", \"guj\"\n",
      "\"hbs\", \"heb\", \"hin\", \"hrv\", \"hun\", \"hye\", \"ind\", \"isl\", \"ita\", \"jpn\"\n",
      "\"kat\", \"kaz\", \"kor\", \"lat\", \"lav\", \"lit\", \"mar\", \"mkd\", \"msa\", \"nld\"\n",
      "\"nno\", \"nor\", \"pol\", \"por\", \"ron\", \"rus\", \"slk\", \"slv\", \"spa\", \"sqi\"\n",
      "\"srp\", \"swa\", \"swe\", \"tam\", \"tel\", \"tgl\", \"tha\", \"tur\", \"ukr\", \"urd\"\n",
      "\"uzb\", \"vie\", \"zho\"\n"
     ]
    }
   ],
   "source": [
    "languages_100_scheme_hosts = df_dataset_all[\"language\"].value_counts().index.tolist()\n",
    "\n",
    "result = \"\"\n",
    "for i, language in enumerate(sorted(languages_100_scheme_hosts)):\n",
    "    result += f\"\\\"{language}\\\"\"\n",
    "    if i + 1 == len(languages_100_scheme_hosts):\n",
    "        pass\n",
    "    elif (i + 1) % 10 != 0:\n",
    "        result += \", \"\n",
    "    else:\n",
    "        result += \"\\n\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 63720\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 7965\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 7965\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_qa(example):\n",
    "    text = f\"{example['question']} ### {example['answer']}\"\n",
    "    if \"title\" in example and example[\"title\"]:\n",
    "        text += f\" ### Title: {example['title']}\"\n",
    "    if \"description\" in example and example[\"description\"]:\n",
    "        text += f\" ### Description: {example['description']}\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "# def concat_qa(example):\n",
    "#     text = f\"{example['question']}\"\n",
    "#     return {\"text\": text}\n",
    "\n",
    "def adapt_label(example):\n",
    "    example[\"label\"] = example[\"label\"] - 1\n",
    "    return example\n",
    "\n",
    "# Apply transformations to all splits\n",
    "dataset = dataset.map(concat_qa)\n",
    "dataset = dataset.map(adapt_label)\n",
    "\n",
    "# Remove columns\n",
    "dataset = dataset.remove_columns([\"language\", \"question\", \"answer\", \"title\", \"description\"])\n",
    "# dataset = dataset.remove_columns([\"language\", \"question\"])\n",
    "\n",
    "# Rename label to labels\n",
    "dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 6,\n",
       " 'text': '¿22 bet es legal en Argentina? ### Sí. La marca no cuenta con una licencia local, pero gracias a las regulaciones vigentes, puede operar sin problemas con su licencia internacional. ### Title: 22 Bet: La mejor casa de apuestas deportivas y eventos deportivos ### Description: Descubra la emoción de las apuestas deportivas con la aplicación, las ofertas de bonos y las completas líneas de apuestas de 22 Bet. ¡Vive la emoción de tus eventos favoritos!'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 3936, 4015, 1600, 198, 8437, 22, 34170, 32, 6, 187284, 22683, 5, 239, 7098, 110, 9472, 158, 220, 95280, 4000, 4, 1788, 21376, 10, 576, 15913, 3825, 124483, 7, 4, 5171, 6264, 42, 880, 12234, 158, 166, 95280, 17228, 5, 6, 187284, 48962, 12, 1039, 6300, 12, 239, 8114, 2349, 8, 177842, 7, 103643, 7, 113, 44938, 157823, 7, 6, 187284, 70643, 12, 6, 177633, 11, 21, 196835, 8, 576, 177842, 7, 103643, 7, 158, 21, 36050, 4, 576, 96722, 8, 337, 2245, 113, 576, 13627, 7, 49975, 7, 8, 177842, 7, 8, 1039, 6300, 5, 14701, 6609, 272, 21, 196835, 8, 15875, 44938, 95333, 7, 38, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretained_model_name)\n",
    "\n",
    "tokenizer(dataset[\"train\"][\"text\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/7965 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7965/7965 [00:02<00:00, 3494.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 63720\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 7965\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 7965\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "dataset = dataset.map(tokenize_text, batched=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    0.291274\n",
       "1    0.139140\n",
       "2    0.071767\n",
       "3    0.290458\n",
       "4    0.058632\n",
       "5    0.063606\n",
       "6    0.045778\n",
       "7    0.039344\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset[\"labels\"].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70872567, 0.86086001, 0.92823289, 0.70954175, 0.94136849,\n",
       "       0.9363936 , 0.95422159, 0.96065599])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1 - df_dataset[\"labels\"].value_counts(normalize=True).sort_index()).values\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7087, 0.8609, 0.9282, 0.7095, 0.9414, 0.9364, 0.9542, 0.9607],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).cuda()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Feed inputs to model and extract logits\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Extract labels\n",
    "        labels = inputs.get(\"labels\")\n",
    "\n",
    "        # Define loss function with class weights\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Return loss and outputs\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretained_model_name,\n",
    "    num_labels=8,\n",
    "    # num_labels=10,\n",
    "    # id2label=id2label,\n",
    "    # label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Log the training loss at each epoch\n",
    "logging_steps = len(dataset[\"train\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_steps=logging_steps,\n",
    "    fp16=True,\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1002883/3045441805.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedLossTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedLossTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = WeightedLossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/webfaq-hvXTwCvE-py3.11/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 20:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.448183</td>\n",
       "      <td>0.860083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.405204</td>\n",
       "      <td>0.870866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.372235</td>\n",
       "      <td>0.880260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367988</td>\n",
       "      <td>0.882646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367115</td>\n",
       "      <td>0.880735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/webfaq-hvXTwCvE-py3.11/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/webfaq-hvXTwCvE-py3.11/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/webfaq-hvXTwCvE-py3.11/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/webfaq-hvXTwCvE-py3.11/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/webfaq-hvXTwCvE-py3.11/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/root/.cache/pypoetry/virtualenvs/webfaq-hvXTwCvE-py3.11/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=625, training_loss=0.43798857421875, metrics={'train_runtime': 1246.4869, 'train_samples_per_second': 255.598, 'train_steps_per_second': 0.501, 'total_flos': 8.38316981403648e+16, 'train_loss': 0.43798857421875, 'epoch': 5.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = os.path.join(\"..\", \"..\", \"..\", \"..\", \"models\", \"webfaq-topic-classification\", \"checkpoint-375\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipeline(\"text-classification\", model=pretrained_model_name, truncation=True, max_length=512, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9905927777290344}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Hampton Inn & Suites Santa Monica ha una piscina? ### S\\u00ec, la struttura dispone di una piscina all'aperto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webfaq-hvXTwCvE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
