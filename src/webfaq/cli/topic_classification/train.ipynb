{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a multilingual topic classification model for Q&A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/webfaq-1cZJAUxg-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from webfaq.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretained_model_name = \"xlm-roberta-base\"\n",
    "finetuned_model_name = \"webfaq-question-topic-classification_3\"\n",
    "\n",
    "resources_dir = os.path.join(\"..\", \"..\", \"..\", \"..\", RESOURCES_FOLDER)\n",
    "model_dir = os.path.join(\"..\", \"..\", \"..\", \"..\", MODELS_FOLDER, finetuned_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['language', 'label', 'question'],\n",
       "        num_rows: 29906\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['language', 'label', 'question'],\n",
       "        num_rows: 3739\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['language', 'label', 'question'],\n",
       "        num_rows: 3738\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"wdc\"\n",
    "\n",
    "# Load annotations file\n",
    "annotations_path = os.path.join(resources_dir, dataset_name, \"qtc_annotations.jsonl\")\n",
    "\n",
    "# Add test split\n",
    "dataset = Dataset.from_json(annotations_path)\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Add validation split\n",
    "dataset_validation_test = dataset[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "dataset[\"validation\"] = dataset_validation_test[\"train\"]\n",
    "dataset[\"test\"] = dataset_validation_test[\"test\"]\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nld</td>\n",
       "      <td>6</td>\n",
       "      <td>Waarom is online marketing belangrijk?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spa</td>\n",
       "      <td>7</td>\n",
       "      <td>¿Cómo me registro en 22Bet?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tha</td>\n",
       "      <td>9</td>\n",
       "      <td>ฉันสามารถดาวน์โหลดรูปภาพจากสไลด์โชว์ TikTok ได...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jpn</td>\n",
       "      <td>7</td>\n",
       "      <td>Chengdu Shuangliu International Airportからホテルまで...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slv</td>\n",
       "      <td>8</td>\n",
       "      <td>Ali deluje povezava Bet365 Slovenija?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  label                                           question\n",
       "0      nld      6             Waarom is online marketing belangrijk?\n",
       "1      spa      7                        ¿Cómo me registro en 22Bet?\n",
       "2      tha      9  ฉันสามารถดาวน์โหลดรูปภาพจากสไลด์โชว์ TikTok ได...\n",
       "3      jpn      7  Chengdu Shuangliu International Airportからホテルまで...\n",
       "4      slv      8              Ali deluje povezava Bet365 Slovenija?"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_all = pd.concat([dataset[\"train\"].to_pandas(), dataset[\"validation\"].to_pandas(), dataset[\"test\"].to_pandas()])\n",
    "df_dataset_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1     6656\n",
       "2     1864\n",
       "3     1686\n",
       "4     3623\n",
       "5     1039\n",
       "6     2462\n",
       "7     4948\n",
       "8     5102\n",
       "9     2830\n",
       "10    7173\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_all[\"label\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "ara    1000\n",
       "aze     269\n",
       "ben     518\n",
       "bul    1000\n",
       "cat     425\n",
       "ces    1000\n",
       "dan    1000\n",
       "deu    1000\n",
       "ell    1000\n",
       "eng    1000\n",
       "est     514\n",
       "fas    1000\n",
       "fin    1000\n",
       "fra    1000\n",
       "heb    1000\n",
       "hin    1000\n",
       "hrv     572\n",
       "hun    1000\n",
       "ind    1000\n",
       "isl     108\n",
       "ita    1000\n",
       "jpn    1000\n",
       "kat     107\n",
       "kaz     151\n",
       "kor    1000\n",
       "lav     461\n",
       "lit     797\n",
       "mar     127\n",
       "msa     444\n",
       "nld    1000\n",
       "nor    1000\n",
       "pol    1000\n",
       "por    1000\n",
       "ron    1000\n",
       "rus    1000\n",
       "slk    1000\n",
       "slv     788\n",
       "spa    1000\n",
       "sqi     112\n",
       "srp     558\n",
       "swe    1000\n",
       "tgl     167\n",
       "tha    1000\n",
       "tur    1000\n",
       "ukr    1000\n",
       "urd     119\n",
       "uzb     146\n",
       "vie    1000\n",
       "zho    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_all[\"language\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ara\", \"aze\", \"ben\", \"bul\", \"cat\", \"ces\", \"dan\", \"deu\", \"ell\", \"eng\"\n",
      "\"est\", \"fas\", \"fin\", \"fra\", \"heb\", \"hin\", \"hrv\", \"hun\", \"ind\", \"isl\"\n",
      "\"ita\", \"jpn\", \"kat\", \"kaz\", \"kor\", \"lav\", \"lit\", \"mar\", \"msa\", \"nld\"\n",
      "\"nor\", \"pol\", \"por\", \"ron\", \"rus\", \"slk\", \"slv\", \"spa\", \"sqi\", \"srp\"\n",
      "\"swe\", \"tgl\", \"tha\", \"tur\", \"ukr\", \"urd\", \"uzb\", \"vie\", \"zho\"\n"
     ]
    }
   ],
   "source": [
    "languages_100_scheme_hosts = df_dataset_all[\"language\"].value_counts().index.tolist()\n",
    "\n",
    "result = \"\"\n",
    "for i, language in enumerate(sorted(languages_100_scheme_hosts)):\n",
    "    result += f\"\\\"{language}\\\"\"\n",
    "    if i + 1 == len(languages_100_scheme_hosts):\n",
    "        pass\n",
    "    elif (i + 1) % 10 != 0:\n",
    "        result += \", \"\n",
    "    else:\n",
    "        result += \"\\n\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 29906\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 3739\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 3738\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def concat_qa(example):\n",
    "#     text = f\"{example['question']} ### {example['answer']}\"\n",
    "#     return {\"text\": text}\n",
    "\n",
    "def concat_qa(example):\n",
    "    text = f\"{example['question']}\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "def adapt_label(example):\n",
    "    example[\"label\"] = example[\"label\"] - 1\n",
    "    return example\n",
    "\n",
    "# Apply transformations to all splits\n",
    "dataset = dataset.map(concat_qa)\n",
    "dataset = dataset.map(adapt_label)\n",
    "\n",
    "# Remove columns\n",
    "# dataset = dataset.remove_columns([\"language\", \"question\", \"answer\"])\n",
    "dataset = dataset.remove_columns([\"language\", \"question\"])\n",
    "\n",
    "# Rename label to labels\n",
    "dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 5, 'text': 'Waarom is online marketing belangrijk?'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 94865, 83, 1118, 7481, 54446, 32, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretained_model_name)\n",
    "\n",
    "tokenizer(dataset[\"train\"][\"text\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3739/3739 [00:00<00:00, 14794.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 29906\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3739\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3738\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "dataset = dataset.map(tokenize_text, batched=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    0.180934\n",
       "1    0.049823\n",
       "2    0.045208\n",
       "3    0.097071\n",
       "4    0.027152\n",
       "5    0.064402\n",
       "6    0.131445\n",
       "7    0.136127\n",
       "8    0.075771\n",
       "9    0.192068\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset[\"labels\"].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81906641, 0.95017722, 0.95479168, 0.90292918, 0.97284826,\n",
       "       0.93559821, 0.86855481, 0.86387347, 0.92422925, 0.80793152])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1 - df_dataset[\"labels\"].value_counts(normalize=True).sort_index()).values\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8191, 0.9502, 0.9548, 0.9029, 0.9728, 0.9356, 0.8686, 0.8639, 0.9242,\n",
       "        0.8079], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).cuda()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Feed inputs to model and extract logits\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Extract labels\n",
    "        labels = inputs.get(\"labels\")\n",
    "\n",
    "        # Define loss function with class weights\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Return loss and outputs\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretained_model_name,\n",
    "    # num_labels=8,\n",
    "    num_labels=10,\n",
    "    # id2label=id2label,\n",
    "    # label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Log the training loss at each epoch\n",
    "logging_steps = len(dataset[\"train\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_steps=logging_steps,\n",
    "    fp16=True,\n",
    "    # push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10775/3045441805.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedLossTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedLossTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = WeightedLossTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1404' max='1404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1404/1404 03:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.232700</td>\n",
       "      <td>0.797994</td>\n",
       "      <td>0.741793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.757600</td>\n",
       "      <td>0.680312</td>\n",
       "      <td>0.781345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.660538</td>\n",
       "      <td>0.785645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1404, training_loss=0.8807794730208198, metrics={'train_runtime': 208.8572, 'train_samples_per_second': 429.566, 'train_steps_per_second': 6.722, 'total_flos': 1.290590240852388e+16, 'train_loss': 0.8807794730208198, 'epoch': 3.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = os.path.join(\"..\", \"..\", \"..\", \"..\", MODELS_FOLDER, \"webfaq-topic-classification_2\", \"checkpoint-936\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipeline(\"text-classification\", model=pretrained_model_name, truncation=True, max_length=512, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9893352389335632}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Hampton Inn & Suites Santa Monica ha una piscina? ### S\\u00ec, la struttura dispone di una piscina all'aperto.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webfaq-1cZJAUxg-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
